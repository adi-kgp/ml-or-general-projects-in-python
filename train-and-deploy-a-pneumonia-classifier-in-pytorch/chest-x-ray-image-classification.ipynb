{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45609ef9-4fae-478e-ab7f-031d7de52381",
   "metadata": {},
   "source": [
    "## Chest X-Ray Image Classification (Whether Pneumonia or not)\n",
    "\n",
    "Data source: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8456b7a5-0367-4b89-b5a5-d05b8c7b8ad8",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24dc3e11-89e3-4ac8-ad0a-e89458f5ed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4dd9c5d-db33-4074-b2d2-6bb3af0c68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label in ['NORMAL', 'PNEUMONIA']:\n",
    "            class_dir = os.path.join(root_dir, label)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                self.image_paths.append(os.path.join(class_dir, img_name))\n",
    "                self.labels.append(0 if label == 'NORMAL' else 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "617c1953-8e75-4242-aed6-d0a69cb1ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddcbb9f6-ae6d-44fc-b197-229d85ae31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PneumoniaDataset(root_dir='data/train', transform=transform)\n",
    "test_dataset = PneumoniaDataset(root_dir='data/test', transform=transform)\n",
    "val_dataset = PneumoniaDataset(root_dir='data/val', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7183049-3c50-4337-a6cf-5c36fd20854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting Train and Test datasets for light computation\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Get the indices for all samples in the dataset\n",
    "all_train_indices = list(range(len(train_dataset)))\n",
    "all_test_indices = list(range(len(test_dataset)))\n",
    "\n",
    "# Randomly sample 10% of the indices\n",
    "train_sample_size = int(0.1 * len(all_train_indices))\n",
    "test_sample_size = int(0.1 * len(all_test_indices))\n",
    "train_sampled_indices = random.sample(all_train_indices, train_sample_size)\n",
    "test_sampled_indices = random.sample(all_test_indices, test_sample_size)\n",
    "\n",
    "# Create a Subset dataset using the sampled indices\n",
    "train_dataset = Subset(train_dataset, train_sampled_indices)\n",
    "test_dataset = Subset(test_dataset, test_sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e35e1ee-ff6c-4d90-9907-e520c3ef3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecaae8bc-2327-45a8-a58b-b19697ccee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2) # NORMAL, PNEUMONIA\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f96e259-c5de-4ea1-8b8f-f141b9c15be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31ac7255-c79b-43ea-b570-87b7432c588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.29726773500442505\n",
      "Validation accuracy: 0.5\n",
      "Epoch 2/10, Loss: 0.16177082061767578\n",
      "Validation accuracy: 0.625\n",
      "Epoch 3/10, Loss: 0.13793668150901794\n",
      "Validation accuracy: 0.5625\n",
      "Epoch 4/10, Loss: 0.0824119821190834\n",
      "Validation accuracy: 0.875\n",
      "Epoch 5/10, Loss: 0.03334307670593262\n",
      "Validation accuracy: 0.75\n",
      "Epoch 6/10, Loss: 0.021180763840675354\n",
      "Validation accuracy: 0.75\n",
      "Epoch 7/10, Loss: 0.020063208416104317\n",
      "Validation accuracy: 0.75\n",
      "Epoch 8/10, Loss: 0.07669175416231155\n",
      "Validation accuracy: 0.75\n",
      "Epoch 9/10, Loss: 0.06072697043418884\n",
      "Validation accuracy: 0.875\n",
      "Epoch 10/10, Loss: 0.02942483127117157\n",
      "Validation accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    print('Validation accuracy:', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b1a1028-c956-48fe-bab7-0141d62afdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9354838709677419\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "\n",
    "model.eval()\n",
    "val_labels = []\n",
    "val_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "torch.save(model.state_dict(), 'pneumonia_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8663912-950a-4afe-9347-c565dc74e9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
